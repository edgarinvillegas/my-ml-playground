{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multi-Layer Perceptron, MNIST\n",
    "---\n",
    "In this notebook, we will train an MLP to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database.\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Load and visualize the data\n",
    "2. Define a neural network\n",
    "3. Train the model\n",
    "4. Evaluate the performance of our trained model on a test dataset!\n",
    "\n",
    "Before we begin, we have to import the necessary libraries for working with data and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%config Completer.use_jedi = False\n",
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Load and Visualize the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n",
    "\n",
    "This cell will create DataLoaders for each of our datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "train_loader_full = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "print(len(train_loader.sampler), len(valid_loader.sampler), len(test_loader.sampler))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loaders con random_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "n = len(train_data)\n",
    "n_val = int(n * valid_size)\n",
    "new_train_data, valid_data = torch.utils.data.random_split(train_data, [n-n_val, n_val])\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(new_train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(train_loader.dataset), len(valid_loader.dataset), len(test_loader.dataset))\n",
    "print(len(train_loader.sampler), len(valid_loader.sampler), len(test_loader.sampler))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "The first step in a classification task is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(labels[idx].item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View an Image in More Detail"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = np.squeeze(images[1])\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "width, height = img.shape\n",
    "thresh = img.max()/2.5\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "        ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Define the Network [Architecture](http://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "The architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 512\n",
    "        hidden_2 = 512\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(28 * 28, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(hidden_2, 10)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "It's recommended that you use cross-entropy loss for classification. If you look at the documentation (linked above), you can see that PyTorch's cross entropy function applies a softmax funtion to the output layer *and* then calculates the log loss."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Train the Network\n",
    "\n",
    "The steps for training/learning from a batch of data are described in the comments below:\n",
    "1. Clear the gradients of all optimized variables\n",
    "2. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "3. Calculate the loss\n",
    "4. Backward pass: compute gradient of the loss with respect to model parameters\n",
    "5. Perform a single optimization step (parameter update)\n",
    "6. Update average training loss\n",
    "\n",
    "The following loop trains for 50 epochs; take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Academic code, good to read, not much to reuse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 3\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, target in valid_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Template code, copy only if it needs high customization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_validate_template(model, train_loader, valid_loader, criterion, optimizer, epochs=1):\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    loaders = { 'train': train_loader, 'valid': valid_loader }\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Make a train and validation pass on every epoch.\n",
    "        for phase in ['train', 'valid']:\n",
    "            correct = 0\n",
    "            epoch_avg_loss = 0            \n",
    "            if phase == 'train':\n",
    "                model.train()            \n",
    "            else:\n",
    "                model.eval() # Disables gradient computation and others           \n",
    "            loader = loaders[phase]\n",
    "            for features, target in loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    features, target = features.cuda(), target.cuda()            \n",
    "                pred = model(features)\n",
    "                loss = criterion(pred, target)\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()                    \n",
    "                    loss.backward()                    \n",
    "                    optimizer.step()\n",
    "                # Get highest scored class    \n",
    "                pred = pred.argmax(dim=1, keepdim=True) \n",
    "                correct += torch.sum(pred == target.view_as(pred)).item()\n",
    "                epoch_avg_loss += loss.item() * features.size(0) # * To undo default loss avg\n",
    "            accuracy = correct / len(loader.dataset)        \n",
    "            epoch_avg_loss /= len(loader.dataset) # loss per input\n",
    "            if phase == 'valid':                \n",
    "                print(f'Epoch {epoch}. Val acc: {round(accuracy*100)}%. Loss: {epoch_avg_loss}')\n",
    "                if epoch_avg_loss < best_valid_loss:                    \n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_valid_loss, epoch_avg_loss))\n",
    "                    torch.save(model.state_dict(), 'model.pt')\n",
    "                    best_valid_loss = epoch_avg_loss                                        \n",
    "                else:\n",
    "                    # Stop if validation loss has increased\n",
    "                    print(f'Validation loss increased from {best_valid_loss} to {epoch_avg_loss}. Stopping...')\n",
    "                    return epoch\n",
    "    return epoch\n",
    "\n",
    "train_validate_template(model, train_loader, valid_loader, criterion, optimizer, epochs=50)\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reusable functions. Also readable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sample usage with plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "from train_validate import train_validate\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "def on_epoch_end(model, epoch, epoch_train_loss, epoch_valid_loss, best_valid_loss, train_metrics, valid_metrics):\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    valid_losses.append(epoch_valid_loss)    \n",
    "    print(f'Epoch {epoch}. Val loss: {epoch_valid_loss}. Train loss: {epoch_train_loss} Val metrics: {valid_metrics} Train metrics: {train_metrics}')\n",
    "    if epoch_valid_loss > best_valid_loss:                    \n",
    "        # Stop if validation loss has increased\n",
    "        print(f'  Validation loss increased from {best_valid_loss} to {epoch_valid_loss}. Stopping...')\n",
    "    else:    \n",
    "        print('  Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_valid_loss, epoch_valid_loss))\n",
    "        \n",
    "\n",
    "best_model_state = train_validate(model, train_loader, valid_loader, criterion, optimizer, epochs=50, on_epoch_end=on_epoch_end, metric_factories={'Acc': torchmetrics.Accuracy}, stop_on_loss_increase=True )\n",
    "model.load_state_dict(best_model_state)\n",
    "torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "print('Done. Saved to model.pt')\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot shifting val loss 1 epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Finally, we test our best model on previously unseen **test data** and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.070808\n",
      "\n",
      "Test Accuracy of     0: 98% (968/980)\n",
      "Test Accuracy of     1: 98% (1122/1135)\n",
      "Test Accuracy of     2: 97% (1007/1032)\n",
      "Test Accuracy of     3: 98% (992/1010)\n",
      "Test Accuracy of     4: 97% (958/982)\n",
      "Test Accuracy of     5: 97% (869/892)\n",
      "Test Accuracy of     6: 97% (937/958)\n",
      "Test Accuracy of     7: 96% (996/1028)\n",
      "Test Accuracy of     8: 97% (946/974)\n",
      "Test Accuracy of     9: 96% (974/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9769/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.cpu()\n",
    "model.eval() # prep model for evaluation\n",
    "\n",
    "for data, target in test_loader:    \n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize Sample Test Results\n",
    "\n",
    "This cell displays test images and their labels in this format: `predicted (ground-truth)`. The text will be green for accurately classified examples and red for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-48bf1d79b703>:15: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds = torch.max(output, 1)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}