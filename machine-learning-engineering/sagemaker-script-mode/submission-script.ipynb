{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-07 03:42:37 Starting - Starting the training job...\n",
      "2022-01-07 03:43:00 Starting - Launching requested ML instancesProfilerReport-1641526956: InProgress\n",
      "......\n",
      "2022-01-07 03:44:01 Starting - Preparing the instances for training.........\n",
      "2022-01-07 03:45:31 Downloading - Downloading input data...\n",
      "2022-01-07 03:46:01 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:17,530 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:17,532 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:17,540 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\n",
      "2022-01-07 03:46:31 Training - Training image download completed. Training in progress.\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:32,492 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:32,495 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:32,503 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:35,535 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:35,912 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:35,926 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:35,937 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-01-07 03:46:35,946 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": \"32\",\n",
      "        \"test-batch-size\": \"64\",\n",
      "        \"lr\": \"0.001\",\n",
      "        \"epochs\": \"10\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"cifar-train-job-2022-01-07-03-42-36-340\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152200895494/cifar-train-job-2022-01-07-03-42-36-340/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar_train_entrypoint\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar_train_entrypoint.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"batch-size\":\"32\",\"epochs\":\"10\",\"lr\":\"0.001\",\"test-batch-size\":\"64\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=cifar_train_entrypoint.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=cifar_train_entrypoint\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-152200895494/cifar-train-job-2022-01-07-03-42-36-340/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":\"32\",\"epochs\":\"10\",\"lr\":\"0.001\",\"test-batch-size\":\"64\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"cifar-train-job-2022-01-07-03-42-36-340\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152200895494/cifar-train-job-2022-01-07-03-42-36-340/source/sourcedir.tar.gz\",\"module_name\":\"cifar_train_entrypoint\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar_train_entrypoint.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"10\",\"--lr\",\"0.001\",\"--test-batch-size\",\"64\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[35mSM_HP_TEST-BATCH-SIZE=64\u001b[0m\n",
      "\u001b[35mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 cifar_train_entrypoint.py --batch-size 32 --epochs 10 --lr 0.001 --test-batch-size 64\u001b[0m\n",
      "\u001b[35margs:  Namespace(batch_size=32, epochs=10, lr=0.001, test_batch_size=64)\u001b[0m\n",
      "\u001b[35mDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\u001b[0m\n",
      "\u001b[35mExtracting ./data/cifar-10-python.tar.gz to ./data\u001b[0m\n",
      "\u001b[35mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.114 algo-2:29 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.509 algo-2:29 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.509 algo-2:29 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.510 algo-2:29 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.511 algo-2:29 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.511 algo-2:29 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:42,980 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:43,354 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:43,367 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:43,377 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-07 03:46:43,385 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": \"32\",\n",
      "        \"test-batch-size\": \"64\",\n",
      "        \"lr\": \"0.001\",\n",
      "        \"epochs\": \"10\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar-train-job-2022-01-07-03-42-36-340\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-152200895494/cifar-train-job-2022-01-07-03-42-36-340/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar_train_entrypoint\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar_train_entrypoint.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":\"32\",\"epochs\":\"10\",\"lr\":\"0.001\",\"test-batch-size\":\"64\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar_train_entrypoint.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar_train_entrypoint\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-152200895494/cifar-train-job-2022-01-07-03-42-36-340/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":\"32\",\"epochs\":\"10\",\"lr\":\"0.001\",\"test-batch-size\":\"64\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar-train-job-2022-01-07-03-42-36-340\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-152200895494/cifar-train-job-2022-01-07-03-42-36-340/source/sourcedir.tar.gz\",\"module_name\":\"cifar_train_entrypoint\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar_train_entrypoint.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"10\",\"--lr\",\"0.001\",\"--test-batch-size\",\"64\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_TEST-BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 cifar_train_entrypoint.py --batch-size 32 --epochs 10 --lr 0.001 --test-batch-size 64\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.547 algo-2:29 INFO hook.py:591] name:fc1.weight count_params:2764800\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.547 algo-2:29 INFO hook.py:591] name:fc1.bias count_params:900\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.547 algo-2:29 INFO hook.py:591] name:fc2.weight count_params:270000\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.547 algo-2:29 INFO hook.py:591] name:fc2.bias count_params:300\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.547 algo-2:29 INFO hook.py:591] name:fc3.weight count_params:27000\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.548 algo-2:29 INFO hook.py:591] name:fc3.bias count_params:90\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.548 algo-2:29 INFO hook.py:591] name:fc4.weight count_params:900\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.548 algo-2:29 INFO hook.py:591] name:fc4.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.548 algo-2:29 INFO hook.py:593] Total Trainable Params: 3064000\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.548 algo-2:29 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[35m[2022-01-07 03:46:43.552 algo-2:29 INFO hook.py:488] Hook is writing from the hook with pid: 29\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [0/50000 (0%)]#011Loss: 2.310222\u001b[0m\n",
      "\u001b[34margs:  Namespace(batch_size=32, epochs=10, lr=0.001, test_batch_size=64)\u001b[0m\n",
      "\u001b[34mDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [3200/50000 (6%)]#011Loss: 2.020603\u001b[0m\n",
      "\u001b[34mExtracting ./data/cifar-10-python.tar.gz to ./data\u001b[0m\n",
      "\u001b[34mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.332 algo-1:29 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.704 algo-1:29 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.705 algo-1:29 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.705 algo-1:29 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.706 algo-1:29 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.706 algo-1:29 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.757 algo-1:29 INFO hook.py:591] name:fc1.weight count_params:2764800\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc1.bias count_params:900\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc2.weight count_params:270000\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc2.bias count_params:300\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc3.weight count_params:27000\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc3.bias count_params:90\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc4.weight count_params:900\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:591] name:fc4.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:593] Total Trainable Params: 3064000\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.758 algo-1:29 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-01-07 03:46:50.760 algo-1:29 INFO hook.py:488] Hook is writing from the hook with pid: 29\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/50000 (0%)]#011Loss: 2.298627\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [6400/50000 (13%)]#011Loss: 1.923619\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [9600/50000 (19%)]#011Loss: 1.892870\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [3200/50000 (6%)]#011Loss: 2.281585\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [12800/50000 (26%)]#011Loss: 2.093432\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/50000 (13%)]#011Loss: 1.799081\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [16000/50000 (32%)]#011Loss: 1.697755\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [9600/50000 (19%)]#011Loss: 1.700411\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/50000 (26%)]#011Loss: 1.683712\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [19200/50000 (38%)]#011Loss: 1.631179\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [16000/50000 (32%)]#011Loss: 1.945032\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [22400/50000 (45%)]#011Loss: 1.891717\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/50000 (38%)]#011Loss: 1.701679\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [22400/50000 (45%)]#011Loss: 1.810461\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [25600/50000 (51%)]#011Loss: 1.691730\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/50000 (51%)]#011Loss: 1.795102\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [28800/50000 (58%)]#011Loss: 1.510259\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [28800/50000 (58%)]#011Loss: 1.851466\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [32000/50000 (64%)]#011Loss: 1.668567\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/50000 (64%)]#011Loss: 2.008226\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [35200/50000 (70%)]#011Loss: 1.530086\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [35200/50000 (70%)]#011Loss: 1.585265\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [38400/50000 (77%)]#011Loss: 1.551191\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/50000 (77%)]#011Loss: 1.480143\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [41600/50000 (83%)]#011Loss: 1.552954\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [41600/50000 (83%)]#011Loss: 2.028685\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [44800/50000 (90%)]#011Loss: 1.483336\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/50000 (90%)]#011Loss: 1.379056\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [48000/50000 (96%)]#011Loss: 1.739547\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [48000/50000 (96%)]#011Loss: 1.702791\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.7809, Accuracy: 3646/10000 (36%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [0/50000 (0%)]#011Loss: 1.799088\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.7248, Accuracy: 3704/10000 (37%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/50000 (0%)]#011Loss: 1.590199\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [3200/50000 (6%)]#011Loss: 1.341472\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [3200/50000 (6%)]#011Loss: 1.556356\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [6400/50000 (13%)]#011Loss: 1.487062\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/50000 (13%)]#011Loss: 2.008915\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [9600/50000 (19%)]#011Loss: 1.614856\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [9600/50000 (19%)]#011Loss: 1.712326\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [12800/50000 (26%)]#011Loss: 1.764138\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/50000 (26%)]#011Loss: 1.679848\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [16000/50000 (32%)]#011Loss: 1.655505\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [16000/50000 (32%)]#011Loss: 1.551525\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [19200/50000 (38%)]#011Loss: 1.577727\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/50000 (38%)]#011Loss: 1.709653\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [22400/50000 (45%)]#011Loss: 1.590621\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [22400/50000 (45%)]#011Loss: 1.607875\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [25600/50000 (51%)]#011Loss: 2.033929\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/50000 (51%)]#011Loss: 1.677014\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [28800/50000 (58%)]#011Loss: 1.477937\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [28800/50000 (58%)]#011Loss: 1.365250\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [32000/50000 (64%)]#011Loss: 1.835511\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/50000 (64%)]#011Loss: 1.691499\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [35200/50000 (70%)]#011Loss: 1.701885\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [35200/50000 (70%)]#011Loss: 1.688279\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [38400/50000 (77%)]#011Loss: 1.335008\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/50000 (77%)]#011Loss: 1.688472\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [41600/50000 (83%)]#011Loss: 1.310990\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [44800/50000 (90%)]#011Loss: 1.655083\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [48000/50000 (96%)]#011Loss: 1.625731\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.6566, Accuracy: 4091/10000 (41%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [0/50000 (0%)]#011Loss: 1.581265\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [3200/50000 (6%)]#011Loss: 1.475788\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [6400/50000 (13%)]#011Loss: 1.698687\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [9600/50000 (19%)]#011Loss: 1.494831\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [12800/50000 (26%)]#011Loss: 1.597389\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [41600/50000 (83%)]#011Loss: 1.672737\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/50000 (90%)]#011Loss: 1.931349\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [48000/50000 (96%)]#011Loss: 1.928088\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.6315, Accuracy: 4119/10000 (41%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/50000 (0%)]#011Loss: 2.024064\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [3200/50000 (6%)]#011Loss: 1.312733\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [6400/50000 (13%)]#011Loss: 1.676996\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [9600/50000 (19%)]#011Loss: 1.784483\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12800/50000 (26%)]#011Loss: 1.621121\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [16000/50000 (32%)]#011Loss: 1.542237\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [16000/50000 (32%)]#011Loss: 1.522361\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [19200/50000 (38%)]#011Loss: 1.451769\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [19200/50000 (38%)]#011Loss: 1.739957\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [22400/50000 (45%)]#011Loss: 1.477830\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [22400/50000 (45%)]#011Loss: 1.611111\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [25600/50000 (51%)]#011Loss: 1.476967\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [25600/50000 (51%)]#011Loss: 1.619620\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [28800/50000 (58%)]#011Loss: 1.399200\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [28800/50000 (58%)]#011Loss: 2.012601\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [32000/50000 (64%)]#011Loss: 1.676955\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [32000/50000 (64%)]#011Loss: 1.441873\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [35200/50000 (70%)]#011Loss: 1.315522\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [35200/50000 (70%)]#011Loss: 1.457404\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [38400/50000 (77%)]#011Loss: 1.579528\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [38400/50000 (77%)]#011Loss: 1.265611\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [41600/50000 (83%)]#011Loss: 1.332870\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [41600/50000 (83%)]#011Loss: 1.656039\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [44800/50000 (90%)]#011Loss: 1.618647\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [44800/50000 (90%)]#011Loss: 1.466591\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [48000/50000 (96%)]#011Loss: 1.400960\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [48000/50000 (96%)]#011Loss: 1.329359\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.5900, Accuracy: 4273/10000 (43%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/50000 (0%)]#011Loss: 1.646021\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.5802, Accuracy: 4295/10000 (43%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [0/50000 (0%)]#011Loss: 1.641582\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [3200/50000 (6%)]#011Loss: 1.551107\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [3200/50000 (6%)]#011Loss: 1.701567\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [6400/50000 (13%)]#011Loss: 1.511656\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [6400/50000 (13%)]#011Loss: 1.412647\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [9600/50000 (19%)]#011Loss: 1.364756\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [9600/50000 (19%)]#011Loss: 1.523235\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12800/50000 (26%)]#011Loss: 1.576273\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [12800/50000 (26%)]#011Loss: 1.370804\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [16000/50000 (32%)]#011Loss: 1.741773\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [16000/50000 (32%)]#011Loss: 1.415808\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [19200/50000 (38%)]#011Loss: 1.528465\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [19200/50000 (38%)]#011Loss: 1.612786\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [22400/50000 (45%)]#011Loss: 1.408686\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [22400/50000 (45%)]#011Loss: 1.431355\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [25600/50000 (51%)]#011Loss: 1.225858\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [25600/50000 (51%)]#011Loss: 1.509266\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [28800/50000 (58%)]#011Loss: 1.322780\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [28800/50000 (58%)]#011Loss: 1.349775\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [32000/50000 (64%)]#011Loss: 1.320411\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [32000/50000 (64%)]#011Loss: 1.416570\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [35200/50000 (70%)]#011Loss: 1.394226\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [35200/50000 (70%)]#011Loss: 1.864936\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [38400/50000 (77%)]#011Loss: 1.593133\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [38400/50000 (77%)]#011Loss: 1.425995\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [41600/50000 (83%)]#011Loss: 1.619320\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [41600/50000 (83%)]#011Loss: 1.248532\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [44800/50000 (90%)]#011Loss: 1.679088\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [44800/50000 (90%)]#011Loss: 1.786365\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [48000/50000 (96%)]#011Loss: 1.582783\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [48000/50000 (96%)]#011Loss: 1.720894\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.5757, Accuracy: 4350/10000 (44%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/50000 (0%)]#011Loss: 1.863244\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.5247, Accuracy: 4527/10000 (45%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [0/50000 (0%)]#011Loss: 1.514313\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [3200/50000 (6%)]#011Loss: 1.842367\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [3200/50000 (6%)]#011Loss: 1.094690\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [6400/50000 (13%)]#011Loss: 1.571729\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [6400/50000 (13%)]#011Loss: 1.824704\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [9600/50000 (19%)]#011Loss: 1.467349\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [9600/50000 (19%)]#011Loss: 1.612517\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [12800/50000 (26%)]#011Loss: 1.683702\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [12800/50000 (26%)]#011Loss: 1.454599\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [16000/50000 (32%)]#011Loss: 1.827169\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [16000/50000 (32%)]#011Loss: 1.354115\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [19200/50000 (38%)]#011Loss: 1.609274\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [19200/50000 (38%)]#011Loss: 1.364877\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [22400/50000 (45%)]#011Loss: 1.723510\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [22400/50000 (45%)]#011Loss: 1.542046\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [25600/50000 (51%)]#011Loss: 1.383129\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [25600/50000 (51%)]#011Loss: 1.635121\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [28800/50000 (58%)]#011Loss: 1.645333\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [28800/50000 (58%)]#011Loss: 1.750514\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [32000/50000 (64%)]#011Loss: 1.354185\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [32000/50000 (64%)]#011Loss: 1.487236\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [35200/50000 (70%)]#011Loss: 1.543319\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [35200/50000 (70%)]#011Loss: 1.776625\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [38400/50000 (77%)]#011Loss: 1.393101\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [38400/50000 (77%)]#011Loss: 1.677468\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [41600/50000 (83%)]#011Loss: 1.276904\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [41600/50000 (83%)]#011Loss: 1.679295\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [44800/50000 (90%)]#011Loss: 1.504531\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [44800/50000 (90%)]#011Loss: 1.685159\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [48000/50000 (96%)]#011Loss: 1.496955\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [48000/50000 (96%)]#011Loss: 1.647414\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.5326, Accuracy: 4419/10000 (44%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/50000 (0%)]#011Loss: 1.252824\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.4776, Accuracy: 4657/10000 (47%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [0/50000 (0%)]#011Loss: 1.446661\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [3200/50000 (6%)]#011Loss: 1.892661\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [3200/50000 (6%)]#011Loss: 1.323366\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [6400/50000 (13%)]#011Loss: 1.303701\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [6400/50000 (13%)]#011Loss: 1.337969\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [9600/50000 (19%)]#011Loss: 1.336406\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [9600/50000 (19%)]#011Loss: 1.399602\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [12800/50000 (26%)]#011Loss: 1.452321\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [12800/50000 (26%)]#011Loss: 1.485787\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [16000/50000 (32%)]#011Loss: 1.569992\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [16000/50000 (32%)]#011Loss: 1.389301\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [19200/50000 (38%)]#011Loss: 1.566152\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [19200/50000 (38%)]#011Loss: 1.535460\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [22400/50000 (45%)]#011Loss: 1.666631\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [22400/50000 (45%)]#011Loss: 1.435760\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [25600/50000 (51%)]#011Loss: 1.510703\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [25600/50000 (51%)]#011Loss: 1.525119\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [28800/50000 (58%)]#011Loss: 1.208601\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [28800/50000 (58%)]#011Loss: 1.484558\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [32000/50000 (64%)]#011Loss: 1.302901\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [32000/50000 (64%)]#011Loss: 1.483260\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [35200/50000 (70%)]#011Loss: 1.547674\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [35200/50000 (70%)]#011Loss: 1.114376\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [38400/50000 (77%)]#011Loss: 1.376615\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [41600/50000 (83%)]#011Loss: 1.654774\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [38400/50000 (77%)]#011Loss: 1.720423\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [44800/50000 (90%)]#011Loss: 1.345944\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [41600/50000 (83%)]#011Loss: 1.652478\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [48000/50000 (96%)]#011Loss: 1.404033\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [44800/50000 (90%)]#011Loss: 1.629672\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.4810, Accuracy: 4744/10000 (47%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/50000 (0%)]#011Loss: 1.158711\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [48000/50000 (96%)]#011Loss: 1.332822\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [3200/50000 (6%)]#011Loss: 1.250368\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.4763, Accuracy: 4651/10000 (47%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [0/50000 (0%)]#011Loss: 1.269344\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [6400/50000 (13%)]#011Loss: 1.357423\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [3200/50000 (6%)]#011Loss: 1.263078\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [9600/50000 (19%)]#011Loss: 1.492469\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [6400/50000 (13%)]#011Loss: 1.528250\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [12800/50000 (26%)]#011Loss: 1.122339\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [9600/50000 (19%)]#011Loss: 1.291131\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [16000/50000 (32%)]#011Loss: 1.268240\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [12800/50000 (26%)]#011Loss: 1.411611\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [19200/50000 (38%)]#011Loss: 1.573249\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [16000/50000 (32%)]#011Loss: 1.360561\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [22400/50000 (45%)]#011Loss: 1.807182\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [19200/50000 (38%)]#011Loss: 1.599676\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [25600/50000 (51%)]#011Loss: 1.266593\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [22400/50000 (45%)]#011Loss: 1.572586\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [28800/50000 (58%)]#011Loss: 1.613653\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [25600/50000 (51%)]#011Loss: 1.429170\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [32000/50000 (64%)]#011Loss: 1.118683\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [28800/50000 (58%)]#011Loss: 1.527826\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [35200/50000 (70%)]#011Loss: 1.391461\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [32000/50000 (64%)]#011Loss: 1.568914\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [38400/50000 (77%)]#011Loss: 1.300866\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [35200/50000 (70%)]#011Loss: 1.287593\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [41600/50000 (83%)]#011Loss: 1.522332\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [38400/50000 (77%)]#011Loss: 1.708373\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [44800/50000 (90%)]#011Loss: 1.159739\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [41600/50000 (83%)]#011Loss: 1.497597\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [48000/50000 (96%)]#011Loss: 1.542136\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [44800/50000 (90%)]#011Loss: 1.273053\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.4778, Accuracy: 4680/10000 (47%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/50000 (0%)]#011Loss: 1.544064\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [48000/50000 (96%)]#011Loss: 1.300813\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [3200/50000 (6%)]#011Loss: 1.306454\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 1.4875, Accuracy: 4679/10000 (47%)\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [0/50000 (0%)]#011Loss: 1.351155\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [6400/50000 (13%)]#011Loss: 1.212043\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [3200/50000 (6%)]#011Loss: 1.586530\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [9600/50000 (19%)]#011Loss: 1.263625\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [6400/50000 (13%)]#011Loss: 1.601829\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [12800/50000 (26%)]#011Loss: 1.216002\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [9600/50000 (19%)]#011Loss: 1.475686\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [16000/50000 (32%)]#011Loss: 1.298263\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [12800/50000 (26%)]#011Loss: 1.662787\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [19200/50000 (38%)]#011Loss: 1.422137\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [16000/50000 (32%)]#011Loss: 1.327672\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [22400/50000 (45%)]#011Loss: 1.055562\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [19200/50000 (38%)]#011Loss: 1.559117\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [25600/50000 (51%)]#011Loss: 1.374469\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "hyperparameters = {\n",
    "    'epochs': '10', \n",
    "    'batch-size': '32',\n",
    "    'test-batch-size': '64',\n",
    "    'lr': '0.001'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='./cifar_train_entrypoint.py',\n",
    "    base_job_name='cifar-train-job',\n",
    "    role=get_execution_role(),\n",
    "    instance_count=2,\n",
    "    instance_type='ml.m5.large',\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36'\n",
    ")\n",
    "\n",
    "#TODO: Start Training\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args:  Namespace(batch_size=32, epochs=2, lr=0.001, test_batch_size=64)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[2022-01-07 02:53:23.621 1-8-1-cpu-py36-ml-t3-medium-05a4a7868130c7575335c53b16c7:512 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-01-07 02:53:23.812 1-8-1-cpu-py36-ml-t3-medium-05a4a7868130c7575335c53b16c7:512 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.279149\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.960337\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.141205\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.927547\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.852081\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.219096\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.830395\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.985771\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.793102\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 2.060616\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.658946\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.800685\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.677736\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.504483\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.651915\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.728832\n",
      "\n",
      "Test set: Average loss: 1.6900, Accuracy: 3910/10000 (39%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.400891\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.791049\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.877736\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.588826\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.612756\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.619748\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.575988\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.682765\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.690750\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.884872\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.852331\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.956846\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.895140\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.595662\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.681710\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.921868\n",
      "\n",
      "Test set: Average loss: 1.6613, Accuracy: 4080/10000 (41%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python cifar_train_entrypoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args:  Namespace(batch_size=32, epochs=10, lr=0.001, test_batch_size=64)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[2022-01-07 03:16:10.706 1-8-1-cpu-py36-ml-t3-medium-05a4a7868130c7575335c53b16c7:753 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-01-07 03:16:10.891 1-8-1-cpu-py36-ml-t3-medium-05a4a7868130c7575335c53b16c7:753 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.307815\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.158087\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.922343\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.856903\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.192722\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.532905\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.760896\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.797519\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.064391\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.672391\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.819197\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.623532\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.945929\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.897247\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.766123\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.884932\n",
      "\n",
      "Test set: Average loss: 1.7598, Accuracy: 3635/10000 (36%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.585579\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.593097\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.978231\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.714775\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.643330\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.836775\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.663689\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.434593\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.578061\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.475439\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.757600\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.786598\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.687041\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.859224\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.677308\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.674886\n",
      "\n",
      "Test set: Average loss: 1.6409, Accuracy: 4288/10000 (43%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.255092\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 2.185690\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.992850\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.439555\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.876457\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.514374\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.903522\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 1.914441\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.442093\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.594076\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.484860\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 1.686512\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.530540\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 1.424591\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.990871\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.287075\n",
      "\n",
      "Test set: Average loss: 1.6413, Accuracy: 4145/10000 (41%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.581819\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 1.899051\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.643760\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 1.687631\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.386234\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 1.721163\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.341708\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 1.461055\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.212924\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 1.858660\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.357768\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 1.414796\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.640813\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 1.547861\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.431774\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 1.267547\n",
      "\n",
      "Test set: Average loss: 1.5189, Accuracy: 4522/10000 (45%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.405131\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 1.817013\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.579437\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 1.299801\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.710238\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 1.435543\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.282364\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 1.626819\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.461295\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 1.419243\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.900465\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 1.573300\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.826850\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 1.439418\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.940675\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 1.489164\n",
      "\n",
      "Test set: Average loss: 1.5329, Accuracy: 4507/10000 (45%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.467575\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 1.770089\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.563147\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 1.551595\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.877186\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 1.387297\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.544678\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 1.268309\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.525191\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 1.801900\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.270772\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 1.390762\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.392277\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 1.512118\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.532109\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 1.347696\n",
      "\n",
      "Test set: Average loss: 1.5152, Accuracy: 4517/10000 (45%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.341180\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 1.526275\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.642997\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 1.220844\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.687305\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 1.682763\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.405120\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 1.425491\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.558860\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 1.288115\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.173522\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 1.398485\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.280490\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 1.495956\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.540038\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 1.239950\n",
      "\n",
      "Test set: Average loss: 1.4729, Accuracy: 4763/10000 (48%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.076556\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 1.437243\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.716897\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 1.436244\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.846721\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 1.380787\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.605814\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 1.215458\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.371710\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 1.482327\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.511815\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 1.449217\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.763736\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 1.571982\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.409726\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 1.539766\n",
      "\n",
      "Test set: Average loss: 1.4562, Accuracy: 4812/10000 (48%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.470103\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 1.333180\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.621878\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 1.297494\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.514819\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 1.371630\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.669932\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 1.489622\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.369823\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 1.215604\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.347458\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 1.163622\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.491670\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 1.095785\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.445369\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 1.259107\n",
      "\n",
      "Test set: Average loss: 1.5060, Accuracy: 4647/10000 (46%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.637113\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 1.677141\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.427301\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 1.217406\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.561039\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 1.312003\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.464044\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 1.364885\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.750713\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 1.854801\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.372837\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 1.217212\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.243206\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 1.635402\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.157410\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 1.142747\n",
      "\n",
      "Test set: Average loss: 1.4289, Accuracy: 4907/10000 (49%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python cifar_train_entrypoint.py --batch-size 32 --epochs 10 --lr 0.001 --test-batch-size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
